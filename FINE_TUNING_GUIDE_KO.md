# Qwen3 파인튜닝 가이드 (형식 학습 중심)

요청 조건 업데이트: **지금은 답변 품질 일반화보다 형식 학습이 우선**이며, 현재 25개 예시는 신뢰도 높은 정답셋이라기보다 출력 형식을 고정하기 위한 데이터로 사용.

## 결론
- 이 목적이라면 **25개로도 시작 가능합니다.**
- 목표를 "정답 생성"이 아니라 "출력 포맷/문체 재현"으로 두면, 소량 SFT(LoRA)로 충분히 효과를 볼 수 있습니다.

---

## 권장 목표 정의 (중요)
학습 목표를 아래처럼 명확히 두는 것을 권장합니다.

1. 메뉴 입력 4개(Appetizer/Main/Drink/Dessert)를 받는다.
2. 항상 동일한 섹션 순서로 출력한다.
   - 5개 pairwise balance
   - Total Score
   - Overall Evaluation
3. 문체(길이, 톤, 문장 구조)를 일정하게 유지한다.

즉, 점수의 절대 정확도보다 **형식 일관성**을 핵심 KPI로 둡니다.

---

## 지금 데이터(25개)로 하는 실전 세팅

### 1) 데이터 준비
아래 스크립트로 `Food combination.txt`를 Qwen SFT용 chat JSONL로 변환:

```bash
python prepare_finetune_dataset.py \
  --input "Food combination.txt" \
  --train-output train.jsonl \
  --val-output val.jsonl \
  --val-ratio 0.2
```

### 2) 학습 세팅 (형식 고정 목적)
- 방식: LoRA / QLoRA
- epoch: 5~15 (소량 데이터이므로 과적합 감수 가능)
- learning rate: 보수적으로 시작 (`1e-5 ~ 5e-5`)
- temperature(추론): `0.2~0.4`
- 핵심: 출력 형식이 깨지지 않도록 system prompt를 고정

### 3) 평가 기준
- 형식 일치율(필수 헤더/순서/스코어 표기)
- 섹션 누락률
- 총점 표기 일관성 (`Total Score: x/100`)

---

## 주의할 점
- 현재 데이터가 완벽한 정답이 아니어도, 형식 학습 목적에는 문제 없습니다.
- 다만 모델은 데이터의 문체와 논리를 그대로 모방하므로, 향후 품질 개선이 필요해지면 데이터 추가/정제가 필요합니다.

---

## 한 줄 실행 방침
**지금은 25개로 LoRA SFT를 진행하고, 목표를 ‘형식/문체 고정’으로 제한해서 운영하는 것이 맞습니다.**
