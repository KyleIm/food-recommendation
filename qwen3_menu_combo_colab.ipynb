{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Rr8CGz0bST1"
   },
   "source": [
    "# Qwen3(4B) 메뉴 조합 점수화 노트북 (Unsloth 스타일)\n",
    "\n",
    "이 노트북은 **Qwen3-4B-Instruct**를 사용해 아래 4개 카테고리에서 1개씩 뽑은 메뉴 조합의 점수를 계산합니다.\n",
    "\n",
    "- Appetizer\n",
    "- Main Dish\n",
    "- Drink\n",
    "- Dessert\n",
    "\n",
    "> Colab에서 바로 실행 가능한 형태로 구성했습니다.\n"
   ],
   "id": "2Rr8CGz0bST1"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3HIULAGBbST9"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os, re\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth  # Do this in local & cloud setups\n",
    "else:\n",
    "    import torch; v = re.match(r'[\\d]{1,}\\.[\\d]{1,}', str(torch.__version__)).group(0)\n",
    "    xformers = 'xformers==' + {'2.10':'0.0.34','2.9':'0.0.33.post1','2.8':'0.0.32.post2'}.get(v, \"0.0.34\")\n",
    "    !pip install sentencepiece protobuf \"datasets==4.3.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
    "    !pip install --no-deps unsloth_zoo bitsandbytes accelerate {xformers} peft trl triton unsloth\n",
    "!pip install transformers==4.56.2\n",
    "!pip install --no-deps trl==0.22.2"
   ],
   "id": "3HIULAGBbST9"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lczvLoqkbSUA"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import itertools\n",
    "from typing import Dict, List\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n"
   ],
   "id": "lczvLoqkbSUA"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "I25nL6YibSUB"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1) 사용자 지정 데이터셋\n",
    "DATASET = {\n",
    "    \"appetizer\": [\n",
    "        \"salad\", \"corn soup\", \"miso soup\", \"house bread\", \"cheese\",\n",
    "        \"cracker\", \"Scotch Egg\", \"mashed potato\", \"nachos\", \"pasta\"\n",
    "    ],\n",
    "    \"main_dish\": [\n",
    "        \"ramen\", \"pizza\", \"fried chicken\", \"sandwich\", \"T-bone steak\",\n",
    "        \"sushi\", \"taco\", \"grilled tofu\", \"fish and chips\", \"paella\"\n",
    "    ],\n",
    "    \"drink\": [\n",
    "        \"coca-cola\", \"red wine\", \"white wine\", \"sake\", \"green tea\",\n",
    "        \"orange juice\", \"coke zero\", \"modelo beer\", \"coffee\", \"water\"\n",
    "    ],\n",
    "    \"dessert\": [\n",
    "        \"orange\", \"grape\", \"pudding\", \"ice cream\", \"tart\",\n",
    "        \"cheesecake\", \"macaron\", \"dango\", \"muffin\", \"churro\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print({k: len(v) for k, v in DATASET.items()})\n",
    "print(\"총 가능한 조합 수:\", len(DATASET[\"appetizer\"]) * len(DATASET[\"main_dish\"]) * len(DATASET[\"drink\"]) * len(DATASET[\"dessert\"]))\n"
   ],
   "id": "I25nL6YibSUB"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8EIsu7-QbSUC"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2) Qwen3 로드 (Unsloth template)\n",
    "max_seq_length = 2048\n",
    "candidate_models = [\n",
    "    \"unsloth/Qwen3-4B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Qwen3-4B-unsloth-bnb-4bit\",\n",
    "    \"Qwen/Qwen3-4B-Instruct\",\n",
    "]\n",
    "\n",
    "last_error = None\n",
    "model = None\n",
    "tokenizer = None\n",
    "model_name = None\n",
    "\n",
    "for candidate in candidate_models:\n",
    "    try:\n",
    "        model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "            model_name = candidate,\n",
    "            max_seq_length = max_seq_length,\n",
    "            dtype = None,      # 자동 선택\n",
    "            load_in_4bit = True,\n",
    "        )\n",
    "        model_name = candidate\n",
    "        break\n",
    "    except Exception as e:\n",
    "        last_error = e\n",
    "        print(f\"[skip] {candidate}: {e}\")\n",
    "\n",
    "if model is None:\n",
    "    raise RuntimeError(\n",
    "        \"Qwen3 모델 로드 실패. candidate_models의 이름을 확인하거나,\"\n",
    "        \"허깅페이스 접근 권한/네트워크 상태를 확인하세요.\"\n",
    "    ) from last_error\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "print(\"Loaded:\", model_name)\n"
   ],
   "id": "8EIsu7-QbSUC"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FDXlM30WbSUD"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a professional menu-pairing evaluator.\n",
    "Given exactly one appetizer, one main dish, one drink, and one dessert,\n",
    "write the response in this exact structure:\n",
    "\n",
    "Appetizer: <item>\n",
    "Main Dish: <item>\n",
    "Drink: <item>\n",
    "Dessert: <item>\n",
    "\n",
    "Appetizer–Main Dish Balance (x/20): <1-2 sentence rationale>\n",
    "\n",
    "Main Dish–Drink Balance (x/20): <1-2 sentence rationale>\n",
    "\n",
    "Main Dish–Dessert Balance (x/20): <1-2 sentence rationale>\n",
    "\n",
    "Appetizer–Dessert Balance (x/20): <1-2 sentence rationale>\n",
    "\n",
    "Drink–Dessert Balance (x/20): <1-2 sentence rationale>\n",
    "\n",
    "Total Score: <0-100>/100\n",
    "\n",
    "Overall Evaluation: <concise summary>\n",
    "\n",
    "Rules:\n",
    "- Output only the final answer. No JSON, no markdown table, no <think> tags.\n",
    "- Keep section order and labels exactly the same.\n",
    "- Use English.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def build_user_prompt(combo: Dict[str, str]) -> str:\n",
    "    \"\"\"prepare_finetune_dataset.py의 user prompt 포맷을 그대로 사용.\"\"\"\n",
    "    return (\n",
    "        \"Evaluate this menu combination with the required format:\\n\"\n",
    "        f\"Appetizer: {combo['appetizer']}\\n\"\n",
    "        f\"Main Dish: {combo['main_dish']}\\n\"\n",
    "        f\"Drink: {combo['drink']}\\n\"\n",
    "        f\"Dessert: {combo['dessert']}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_total_score(text: str):\n",
    "    import re\n",
    "\n",
    "    if not text:\n",
    "        return None\n",
    "\n",
    "    cleaned = re.sub(r\"<think>[\\s\\S]*?</think>\", \"\", text, flags=re.IGNORECASE).strip()\n",
    "    m = re.search(r\"Total Score:\\s*(\\d{1,3})\\s*/\\s*100\", cleaned, flags=re.IGNORECASE)\n",
    "    if not m:\n",
    "        return None\n",
    "\n",
    "    score = int(m.group(1))\n",
    "    return max(0, min(100, score))\n",
    "\n",
    "\n",
    "def evaluate_combo_with_qwen3(combo: Dict[str, str], max_new_tokens: int = 512):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": build_user_prompt(combo)},\n",
    "    ]\n",
    "\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            temperature=0.2,\n",
    "            repetition_penalty=1.05,\n",
    "        )\n",
    "\n",
    "    generated = tokenizer.decode(outputs[0][inputs.shape[-1]:], skip_special_tokens=True).strip()\n",
    "    total_score = extract_total_score(generated)\n",
    "    return {\"total_score\": total_score, \"response\": generated}\n"
   ],
   "id": "FDXlM30WbSUD"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GH8jglYObSUD"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3) 카테고리별 1개씩 랜덤으로 뽑아 형식 출력 확인\n",
    "\n",
    "def sample_combo(seed: int = None) -> Dict[str, str]:\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    return {\n",
    "        \"appetizer\": random.choice(DATASET[\"appetizer\"]),\n",
    "        \"main_dish\": random.choice(DATASET[\"main_dish\"]),\n",
    "        \"drink\": random.choice(DATASET[\"drink\"]),\n",
    "        \"dessert\": random.choice(DATASET[\"dessert\"]),\n",
    "    }\n",
    "\n",
    "combo = sample_combo(seed=42)\n",
    "result = evaluate_combo_with_qwen3(combo)\n",
    "\n",
    "print(\"선택된 조합:\")\n",
    "print(combo)\n",
    "print(\"\\n모델 출력:\")\n",
    "print(result[\"response\"])\n",
    "print(\"\\n추출된 Total Score:\", result[\"total_score\"])\n",
    "\n"
   ],
   "id": "GH8jglYObSUD"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X7uA7DfUbSUE"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "# (옵션) 랜덤 3개 조합 평가 후 Total Score 기준 정렬\n",
    "\n",
    "def evaluate_three_random(seed: int = 0) -> List[Dict]:\n",
    "    random.seed(seed)\n",
    "    rows = []\n",
    "\n",
    "    for _ in range(3):\n",
    "        combo = sample_combo()\n",
    "        result = evaluate_combo_with_qwen3(combo)\n",
    "        rows.append({\n",
    "            \"combo\": combo,\n",
    "            \"total_score\": result[\"total_score\"],\n",
    "            \"response\": result[\"response\"],\n",
    "        })\n",
    "\n",
    "    rows.sort(key=lambda x: x[\"total_score\"] if x[\"total_score\"] is not None else -1, reverse=True)\n",
    "    return rows\n",
    "\n",
    "ranked = evaluate_three_random(seed=7)\n",
    "for i, row in enumerate(ranked, 1):\n",
    "    print(f\"#{i} | total_score={row['total_score']} | {row['combo']}\")\n",
    "    print(row['response'])\n",
    "    print()\n",
    "\n"
   ],
   "id": "X7uA7DfUbSUE"
  }
 ],
 "metadata": {
  "colab": {
   "name": "qwen3_menu_combo_colab.ipynb",
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}