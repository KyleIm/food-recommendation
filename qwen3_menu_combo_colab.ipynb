{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Rr8CGz0bST1"
   },
   "source": [
    "# Qwen3(4B) 메뉴 조합 점수화 노트북 (Unsloth 스타일)\n",
    "\n",
    "이 노트북은 **Qwen3-4B-Instruct**를 사용해 아래 4개 카테고리에서 1개씩 뽑은 메뉴 조합의 점수를 계산합니다.\n",
    "\n",
    "- Appetizer\n",
    "- Main Dish\n",
    "- Drink\n",
    "- Dessert\n",
    "\n",
    "> Colab에서 바로 실행 가능한 형태로 구성했습니다.\n"
   ],
   "id": "2Rr8CGz0bST1"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3HIULAGBbST9"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os, re\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth  # Do this in local & cloud setups\n",
    "else:\n",
    "    import torch; v = re.match(r'[\\d]{1,}\\.[\\d]{1,}', str(torch.__version__)).group(0)\n",
    "    xformers = 'xformers==' + {'2.10':'0.0.34','2.9':'0.0.33.post1','2.8':'0.0.32.post2'}.get(v, \"0.0.34\")\n",
    "    !pip install sentencepiece protobuf \"datasets==4.3.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
    "    !pip install --no-deps unsloth_zoo bitsandbytes accelerate {xformers} peft trl triton unsloth\n",
    "!pip install transformers==4.56.2\n",
    "!pip install --no-deps trl==0.22.2"
   ],
   "id": "3HIULAGBbST9"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lczvLoqkbSUA"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import itertools\n",
    "from typing import Dict, List\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n"
   ],
   "id": "lczvLoqkbSUA"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "I25nL6YibSUB"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1) 사용자 지정 데이터셋\n",
    "DATASET = {\n",
    "    \"appetizer\": [\n",
    "        \"salad\", \"corn soup\", \"miso soup\", \"house bread\", \"cheese\",\n",
    "        \"cracker\", \"Scotch Egg\", \"mashed potato\", \"nachos\", \"pasta\"\n",
    "    ],\n",
    "    \"main_dish\": [\n",
    "        \"ramen\", \"pizza\", \"fried chicken\", \"sandwich\", \"T-bone steak\",\n",
    "        \"sushi\", \"taco\", \"grilled tofu\", \"fish and chips\", \"paella\"\n",
    "    ],\n",
    "    \"drink\": [\n",
    "        \"coca-cola\", \"red wine\", \"white wine\", \"sake\", \"green tea\",\n",
    "        \"orange juice\", \"coke zero\", \"modelo beer\", \"coffee\", \"water\"\n",
    "    ],\n",
    "    \"dessert\": [\n",
    "        \"orange\", \"grape\", \"pudding\", \"ice cream\", \"tart\",\n",
    "        \"cheesecake\", \"macaron\", \"dango\", \"muffin\", \"churro\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print({k: len(v) for k, v in DATASET.items()})\n",
    "print(\"총 가능한 조합 수:\", len(DATASET[\"appetizer\"]) * len(DATASET[\"main_dish\"]) * len(DATASET[\"drink\"]) * len(DATASET[\"dessert\"]))\n"
   ],
   "id": "I25nL6YibSUB"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8EIsu7-QbSUC"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2) Qwen3 로드 (Unsloth template)\n",
    "max_seq_length = 2048\n",
    "candidate_models = [\n",
    "    \"unsloth/Qwen3-4B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Qwen3-4B-unsloth-bnb-4bit\",\n",
    "    \"Qwen/Qwen3-4B-Instruct\",\n",
    "]\n",
    "\n",
    "last_error = None\n",
    "model = None\n",
    "tokenizer = None\n",
    "model_name = None\n",
    "\n",
    "for candidate in candidate_models:\n",
    "    try:\n",
    "        model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "            model_name = candidate,\n",
    "            max_seq_length = max_seq_length,\n",
    "            dtype = None,      # 자동 선택\n",
    "            load_in_4bit = True,\n",
    "        )\n",
    "        model_name = candidate\n",
    "        break\n",
    "    except Exception as e:\n",
    "        last_error = e\n",
    "        print(f\"[skip] {candidate}: {e}\")\n",
    "\n",
    "if model is None:\n",
    "    raise RuntimeError(\n",
    "        \"Qwen3 모델 로드 실패. candidate_models의 이름을 확인하거나,\"\n",
    "        \"허깅페이스 접근 권한/네트워크 상태를 확인하세요.\"\n",
    "    ) from last_error\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "print(\"Loaded:\", model_name)\n"
   ],
   "id": "8EIsu7-QbSUC"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FDXlM30WbSUD"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a food pairing evaluator.\n",
    "Given exactly one appetizer, one main dish, one drink, and one dessert,\n",
    "return a strict JSON object with fields:\n",
    "- score: integer from 0 to 100\n",
    "- reason: short explanation in Korean\n",
    "Scoring criteria:\n",
    "1) Flavor harmony (40)\n",
    "2) Texture balance (20)\n",
    "3) Temperature/course flow (20)\n",
    "4) Overall coherence (20)\n",
    "Do NOT output any analysis, chain-of-thought, or <think> tags.\n",
    "Return ONLY one-line JSON like: {\"score\": 82, \"reason\": \"맛의 밸런스가 안정적입니다.\"}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def build_user_prompt(combo: Dict[str, str]) -> str:\n",
    "    return (\n",
    "        \"아래 4개 메뉴 조합을 0~100점으로 평가하세요.\\n\"\n",
    "        \"반드시 JSON 1줄만 출력하세요. 다른 텍스트/태그 금지.\\n\"\n",
    "        '형식: {\"score\": 0~100 정수, \"reason\": \"한국어 한 줄\"}\\n\\n'\n",
    "        f\"appetizer: {combo['appetizer']}\\n\"\n",
    "        f\"main_dish: {combo['main_dish']}\\n\"\n",
    "        f\"drink: {combo['drink']}\\n\"\n",
    "        f\"dessert: {combo['dessert']}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def parse_json_from_text(text: str):\n",
    "    import re\n",
    "\n",
    "    if not text:\n",
    "        return None\n",
    "\n",
    "    cleaned = re.sub(r\"<think>[\\s\\S]*?</think>\", \"\", text, flags=re.IGNORECASE).strip()\n",
    "\n",
    "    # 1) direct JSON parse\n",
    "    try:\n",
    "        data = json.loads(cleaned)\n",
    "        if isinstance(data, dict) and \"score\" in data and \"reason\" in data:\n",
    "            data[\"score\"] = int(float(data[\"score\"]))\n",
    "            return data\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2) parse the biggest {...} chunk\n",
    "    start = cleaned.find('{')\n",
    "    end = cleaned.rfind('}')\n",
    "    if start != -1 and end != -1 and end > start:\n",
    "        chunk = cleaned[start:end + 1]\n",
    "        for candidate in (chunk, chunk.replace(\"'\", '\"')):\n",
    "            try:\n",
    "                data = json.loads(candidate)\n",
    "                if isinstance(data, dict) and \"score\" in data and \"reason\" in data:\n",
    "                    data[\"score\"] = int(float(data[\"score\"]))\n",
    "                    return data\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    # 3) heuristic extraction for semi-structured text\n",
    "    score_m = re.search(r'\"?score\"?\\s*[:=]\\s*\"?(\\d{1,3})\"?', cleaned, flags=re.IGNORECASE)\n",
    "    reason_m = re.search(r'\"?reason\"?\\s*[:=]\\s*\"([^\"\\\\n]+)\"', cleaned, flags=re.IGNORECASE)\n",
    "    if not reason_m:\n",
    "        reason_m = re.search(r'reason\\s*[:=]\\s*(.+)', cleaned, flags=re.IGNORECASE)\n",
    "\n",
    "    if score_m and reason_m:\n",
    "        score = max(0, min(100, int(score_m.group(1))))\n",
    "        reason = reason_m.group(1).strip()\n",
    "        return {\"score\": score, \"reason\": reason}\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def repair_output_to_json(combo: Dict[str, str], raw_text: str, max_new_tokens: int = 128):\n",
    "    \"\"\"파싱 실패 시 모델에게 JSON 정규화만 재요청.\"\"\"\n",
    "    repair_messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"Convert the following evaluation to strict JSON only. \"\n",
    "                \"Output exactly one line: {\\\"score\\\": int(0-100), \\\"reason\\\": \\\"한국어 한 줄\\\"}.\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"combo={combo}\\n\"\n",
    "                f\"raw_output={raw_text}\"\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    repair_inputs = tokenizer.apply_chat_template(\n",
    "        repair_messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        repair_outputs = model.generate(\n",
    "            input_ids=repair_inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            repetition_penalty=1.05,\n",
    "        )\n",
    "\n",
    "    repaired = tokenizer.decode(\n",
    "        repair_outputs[0][repair_inputs.shape[-1]:], skip_special_tokens=True\n",
    "    )\n",
    "    return repaired\n",
    "\n",
    "\n",
    "def evaluate_combo_with_qwen3(combo: Dict[str, str], max_new_tokens: int = 512):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": build_user_prompt(combo)},\n",
    "    ]\n",
    "\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            repetition_penalty=1.05,\n",
    "        )\n",
    "\n",
    "    generated = tokenizer.decode(outputs[0][inputs.shape[-1]:], skip_special_tokens=True)\n",
    "    parsed = parse_json_from_text(generated)\n",
    "\n",
    "    # 1차 파싱 실패 시 JSON 변환 재요청(결과 안정성 향상)\n",
    "    if parsed is None:\n",
    "        repaired = repair_output_to_json(combo, generated)\n",
    "        reparsed = parse_json_from_text(repaired)\n",
    "        if reparsed is not None:\n",
    "            return reparsed, f\"{generated}\\n[REPAIRED] {repaired}\"\n",
    "\n",
    "    return parsed, generated\n",
    "\n"
   ],
   "id": "FDXlM30WbSUD"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GH8jglYObSUD"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3) 카테고리별 1개씩 랜덤으로 뽑아 점수 계산\n",
    "\n",
    "def sample_combo(seed: int = None) -> Dict[str, str]:\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    return {\n",
    "        \"appetizer\": random.choice(DATASET[\"appetizer\"]),\n",
    "        \"main_dish\": random.choice(DATASET[\"main_dish\"]),\n",
    "        \"drink\": random.choice(DATASET[\"drink\"]),\n",
    "        \"dessert\": random.choice(DATASET[\"dessert\"]),\n",
    "    }\n",
    "\n",
    "combo = sample_combo(seed=42)\n",
    "result, raw = evaluate_combo_with_qwen3(combo)\n",
    "\n",
    "print(\"선택된 조합:\")\n",
    "print(combo)\n",
    "print(\"\\n모델 원문 출력:\")\n",
    "print(raw)\n",
    "print(\"\\n파싱 결과:\")\n",
    "print(result)\n"
   ],
   "id": "GH8jglYObSUD"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X7uA7DfUbSUE"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "# (옵션) 랜덤 3개 조합만 평가해서 고득점 순으로 보기\n",
    "\n",
    "def evaluate_three_random(seed: int = 0) -> List[Dict]:\n",
    "    random.seed(seed)\n",
    "    rows = []\n",
    "\n",
    "    for _ in range(3):\n",
    "        combo = sample_combo()\n",
    "        parsed, raw = evaluate_combo_with_qwen3(combo)\n",
    "        score = parsed.get(\"score\") if parsed else None\n",
    "        reason = parsed.get(\"reason\") if parsed else f\"파싱 실패: {raw[:160]}\"\n",
    "        rows.append({\"combo\": combo, \"score\": score, \"reason\": reason})\n",
    "\n",
    "    rows.sort(key=lambda x: x[\"score\"] if x[\"score\"] is not None else -1, reverse=True)\n",
    "    return rows\n",
    "\n",
    "ranked = evaluate_three_random(seed=7)\n",
    "for i, row in enumerate(ranked, 1):\n",
    "    print(f\"#{i} | score={row['score']} | {row['combo']}\\n  reason={row['reason']}\\n\")\n"
   ],
   "id": "X7uA7DfUbSUE"
  }
 ],
 "metadata": {
  "colab": {
   "name": "qwen3_menu_combo_colab.ipynb",
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}